{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGKAZlCh02cl"
   },
   "source": [
    "# Introduction to Neural Networking in Keras\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/coding-dojo-data-science/week-11-lecture-2-tuning-deep-learning-models/blob/main/Code-along%20Tuning%20Neural%20Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OStduN-207_9"
   },
   "source": [
    "We will use the version of Keras that comes in the Tensorflow package, as it has the most up to date tools.\n",
    "\n",
    "Keras works as weapper for deep learning model to be used as classification or regression estimators in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1669773653478,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "Zw6CH1mp0zR4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import heatmap\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, \\\n",
    "precision_score, recall_score, accuracy_score, f1_score, ConfusionMatrixDisplay, \\\n",
    "classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# new libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Set random seeds for consistent outcomes\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5pga5rHChPu"
   },
   "source": [
    "### Plot History\n",
    "\n",
    "Since we will be plotting histories for all of our models, lets create a function to do it quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T22:57:00.803078Z",
     "start_time": "2023-02-07T22:57:00.793142Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1669773653823,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "UbrKqMv0_28Q"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  \"\"\"Takes a keras model learning history and plots each metric\"\"\"\n",
    "  \n",
    "  metrics = history.history.keys()\n",
    "  \n",
    "  for metric in metrics:\n",
    "      if not 'val' in metric:\n",
    "        plt.plot(history.history[f'{metric}'], label=f'{metric}')\n",
    "        if f'val_{metric}' in metrics:\n",
    "          plt.plot(history.history[f'val_{metric}'], label=f'val_{metric}')\n",
    "        plt.legend()\n",
    "        plt.title(f'{metric}')\n",
    "        plt.show()\n",
    "        \n",
    "def eval_regression(true, pred, name='Model'):\n",
    "    \"\"\"Evaluates true and predicted values from a regression model.  \n",
    "    Outputs a dataframe of metrics\"\"\"\n",
    "    scores = pd.DataFrame()\n",
    "    scores['Model Name'] = [name]\n",
    "    scores['RMSE'] = [np.sqrt(mean_squared_error(true, pred))]\n",
    "    scores['MAE'] = [mean_absolute_error(true, pred)]\n",
    "    scores['R2'] = [r2_score(true, pred)]\n",
    "    scores.set_index('Model Name', inplace=True)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAUUTWm93ojP"
   },
   "source": [
    "# Data\n",
    "\n",
    "We will be working with 2 different datasets in this project, 1 is a regression dataset and the other is a classification dataset.  This way you can practice doing both using deep learning.\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "These datasets are very small for deep learning.  Deep learning models usually work best with very large datasets with at least 10,000 or more samples.  They work best on even larger datasets than that.  But, for demonstration we will use these smaller datasets.\n",
    "\n",
    "## Regression\n",
    "This is a dataset of housing prices in Boston from 1978.  Each row is a house and the dataset includes several features regarding each house.  Our target today will be the price of the home.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1669773653824,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "8_PM7Bt81FKh"
   },
   "outputs": [],
   "source": [
    "regression_df = pd.read_csv('https://raw.githubusercontent.com/ninja-josh/image-storage/main/Boston_Housing_from_Sklearn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YPAPvdG6Sqy"
   },
   "source": [
    "# Regression\n",
    "\n",
    "Let's start with modeling the regression dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1669773653825,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "3STtBugN3fp1",
    "outputId": "a196c50e-5214-4291-d748-8f886e5f1ae0"
   },
   "outputs": [],
   "source": [
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1669773653825,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "4sJoxV1ZJKBd",
    "outputId": "e21badc3-d359-42b4-ca36-aa29500f42b7"
   },
   "outputs": [],
   "source": [
    "regression_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1669773653827,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "uvcvdJUZ6YKX",
    "outputId": "3782efbc-4b4c-4789-c759-9bea2f126742"
   },
   "outputs": [],
   "source": [
    "regression_df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1669773653827,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "IrxmHTaU6s3N",
    "outputId": "4d3960ea-92b8-4d94-ddde-7563ae782286"
   },
   "outputs": [],
   "source": [
    "regression_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1669773653827,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "rU0zM_dk6xDd"
   },
   "outputs": [],
   "source": [
    "# Define X and Y and complete the train test split\n",
    "X = regression_df.drop(columns = 'PRICE')\n",
    "y = regression_df['PRICE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqS765vN8Xti"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "Always scale your data for deep learning.  Otherwise you get a problem call 'Exploding Weights'.  Some weights will be updated much faster than others because the inputs are at larger scales.  This tends to hurt learning as data on smaller scales does not update as fast and doesn't get to contribute as much to the decision making process.  By scaling we put all features on the same footing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1669773653828,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "bvCCtAhQ7gGe"
   },
   "outputs": [],
   "source": [
    "# Scale the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzX4RBcu8TFx"
   },
   "source": [
    "## First Simple Model\n",
    "\n",
    "We always want to start simple, as deep learning models can get very complex fast and more complex models take more time to train and are more prone to overfitting.  A well performing simple model is better than a well performing complex model.\n",
    "\n",
    "## Input layer\n",
    "The first layer we will define is not technically the input layer.  We will define the first hidden layer with a special argument that tells Keras how to create a input layer:\n",
    "\n",
    "`input_dim=`\n",
    "\n",
    "Input layers can also be defined manually using tensorflow.keras.layers.InputLayer\n",
    "\n",
    "## Activation function\n",
    "\n",
    "For the single hidden layer we will try just 3 nodes and use a ReLU activation.  ReLUs tend to perform well for hidden layers.\n",
    "\n",
    "## Output Layer\n",
    "\n",
    "For out output layer (last layer) we just use one node because we only want the output of the model to be one number.  We will use a linear activation function.  This will simply output the value from the weights and bias in the node with no change.  The output will be a continuous number, a float.  This will make our model a regression model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glnm6hhh4M6u"
   },
   "source": [
    "# Note:\n",
    "### The first layer you define will NOT be the input layer!  Keras will create an input layer on its own, implicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1137,
     "status": "ok",
     "timestamp": 1669773856315,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "AnjwY1dz7vcG",
    "outputId": "6937a96c-d31f-4bbb-a436-7d0acd5a0779"
   },
   "outputs": [],
   "source": [
    "# Set Random Seeds\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Instantiate your sequential model\n",
    "\n",
    "# Add first hidden layer with 3 neurons THIS IS NOT THE INPUT LAYER!\n",
    "\n",
    "# Tell Keras how to construct the input layer shape using input_dim\n",
    "\n",
    "# Add output layer with 1 node\n",
    "\n",
    "# Check summary of network \n",
    "\n",
    "# Compile your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wAFuCDGOBzo"
   },
   "source": [
    "## Compiling\n",
    "\n",
    "Compiling the model puts all the pieces together to make it ready to train.  \n",
    "\n",
    "For this step, we need to specify a few other hyperparameters:\n",
    "\n",
    "* **Optimizer:** An Adam optimizer is a favorite and often performs well, it's a good place to start.\n",
    "  - Other optimizers : Gradient Descent, Stochastic Gradient Descent, Adagrad, RMSProp\n",
    "* **Loss Function:** 'mse' or mean squared error.  This is the number our model will try to reduce in each epoch.  Since this is a regression model we want our model to minimize the mean squared error.  A loss function ALWAYS needs to be a measurement of the total error that the model can REDUCE.  R^2 won't work because higher is better. We don't want the model to reduce R^2!\n",
    "* **Metrics:** 'mae' or mean absolute error.  We can provide a list of any appropriate metrics we want the model to keep track at each epoch.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1669774254064,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "AwAGvWCZN1WC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBvS_wkr_hEh"
   },
   "source": [
    "# Training (AKA fitting)\n",
    "\n",
    "Let's try training our model for 100 few epochs.  Sometimes that is enough, and it will give us an idea whether our model is learning anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7789,
     "status": "ok",
     "timestamp": 1669774262233,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "81VFx1n1-TS7",
    "outputId": "c2605944-1180-4dce-85a6-33bb44d902db"
   },
   "outputs": [],
   "source": [
    "# Fit your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1669774262233,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "q8Kox9hOOq7w",
    "outputId": "735158f1-5a46-49a6-ed9c-dbdd527fdd6f"
   },
   "outputs": [],
   "source": [
    "# Apply the custom function plot_history() to see how your model is doing\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ic8eFsL_x2m"
   },
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1669774452839,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "33J5dOt3A8ZO",
    "outputId": "2720b756-e7e9-4c79-c43f-a95b778d34a1"
   },
   "outputs": [],
   "source": [
    "# Make predictions and evaluate your model\n",
    "train_preds = reg_model.predict(X_train)\n",
    "test_preds = reg_model.predict(X_test)\n",
    "\n",
    "train_scores = eval_regression(y_train, train_preds, name='base_reg_train')\n",
    "test_scores = eval_regression(y_test, test_preds, name='base_reg_test')\n",
    "\n",
    "reg_scores = pd.concat([train_scores, test_scores])\n",
    "reg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvQ16n8x7RWb"
   },
   "source": [
    "# <center> Temperature Check: </center>\n",
    "## On a scale of 0 - 5, how confident do you feel in coding neural networks?\n",
    "\n",
    "0. What is a neural net?\n",
    "1. I know what a neural net is, but I don't know how to even start coding one.\n",
    "2. I kinda get how the code flows, but need help from someone else to create my own.\n",
    "3. I understand the general idea, and could code a neural net in Keras if I had an example in front of me.\n",
    "4. I feel confident in coding a neural network with some reference materials.\n",
    "5. Move over, Josh.  I can finish this code-along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWaTq6c7FHlr"
   },
   "source": [
    "\n",
    "# ðŸ¦¾ Your Turn: Classification Models in Keras\n",
    "\n",
    "Classification models are similar, except that we need to adjust:\n",
    "* The final activation of the output layer, and\n",
    "* The loss function and metrics in the compile step.\n",
    "\n",
    "We will also need to do some processing of the predictions after training to make them integers instead of floats.\n",
    "\n",
    "### Remember: \n",
    "MAE, MSE, RMSE, and R2 are regression metrics,\n",
    "\n",
    "accuracy, recall, precision, and F1-Score are classification metrics.\n",
    "\n",
    "## Classification Dataset\n",
    "The classification dataset describes diabetes rates among Pima Indians.  Each row is a person and this dataset includes features regarding health related measurements.  The target is binary and represents whether or not a person will diagnosed with diabetes.  This is another old dataset first presented in 1988.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1669774541923,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "CN1zHoGcGeFN",
    "outputId": "6c6487ec-caf3-4432-f401-550f96c75d4d"
   },
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv('https://raw.githubusercontent.com/ninja-josh/image-storage/main/diabetes.csv')\n",
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1669774542269,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "isTaHNFpGjQH",
    "outputId": "326d26fd-39d6-42f6-bb95-595661f0b8ef"
   },
   "outputs": [],
   "source": [
    "classification_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1669774542626,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "HtZv-V73Gmjv",
    "outputId": "ec618407-febf-418b-c256-89b4392899c6"
   },
   "outputs": [],
   "source": [
    "classification_df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1669774542626,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "sdF3qT-9Gp_s",
    "outputId": "4c087cd0-fb3a-41c3-a19b-c8e5aa05e430"
   },
   "outputs": [],
   "source": [
    "classification_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8cjiy3BGvLa"
   },
   "source": [
    "We see minimums for Glucose, BloodPression, SkinThickness, Insulin, and BMI of 0s.  Those are impossible for humans, so lets drop those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1669774584831,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "TwzoeFVWG6Dd",
    "outputId": "a06e6f2c-a4bc-4e63-e8ce-13d575fc7514"
   },
   "outputs": [],
   "source": [
    "no_glucose = classification_df['Glucose'] == 0\n",
    "no_blood = classification_df['BloodPressure'] == 0\n",
    "no_skin = classification_df['SkinThickness'] == 0\n",
    "no_insulin = classification_df['Insulin'] == 0\n",
    "no_bmi = classification_df['BMI'] == 0\n",
    "\n",
    "#class_df_clean excludes rows that have no values == 0 in the above columns\n",
    "class_df_clean = classification_df[~(no_glucose |\n",
    "                                     no_blood |\n",
    "                                     no_skin |\n",
    "                                     no_insulin |\n",
    "                                     no_bmi)]\n",
    "class_df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQqWsTbaM5It"
   },
   "source": [
    "We lost a lot of data, going from 768 samples to 392 samples.  In the future we might impute this data using means, medians, or other imputation strategies.  For this exercise we won't focus on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1669774587774,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "JjREwrWgGPtP"
   },
   "outputs": [],
   "source": [
    "# Define X and y and train test split\n",
    "X = class_df_clean.drop(columns = 'Outcome')\n",
    "y = class_df_clean['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1669774588612,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "EKPiCOByPOfF"
   },
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TWU179nQIdt"
   },
   "source": [
    "## Build the Classification Model\n",
    "\n",
    "We need to do a few things differently here because this is a binary classification:\n",
    "\n",
    "1. The activation of our final layer needs to be 'sigmoid'.  \n",
    "\n",
    "\n",
    "(If this were multiclass classification, we would set the final activation as 'softmax' and the number of output nodes would be the number of classes in our y_train.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1669774743589,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "lAwy3AXrPjwH",
    "outputId": "254c307c-9295-4950-9b14-671f2250be59"
   },
   "outputs": [],
   "source": [
    "# Set Random Seeds\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Build your model\n",
    "\n",
    "# One output node with 'sigmoid' activation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nrwLXyKPpO1"
   },
   "source": [
    "## More Changes for Classification:\n",
    "\n",
    "1.  We need to change our loss to 'binary_crossentropy', or 'bce'.  If this were multiclass we would use 'categorical_crossentrobpy'.\n",
    "\n",
    "2. Our metrics should be classification metrics.  We will use accuracy and import recall and precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1669774839694,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "GOe9CMP2PtDT"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "# Compile your model with loss='bce, set metrics = ['acc', Precision(), Recall()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2160,
     "status": "ok",
     "timestamp": 1669774872903,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "vScTvfoKOVLO",
    "outputId": "6df75278-6e74-43d0-d7f7-5b6a0f119e92"
   },
   "outputs": [],
   "source": [
    "# fit your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1669774881591,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "qKLxgYDcP0_H",
    "outputId": "2912bcb6-ba09-4f38-d472-0691e7524b43"
   },
   "outputs": [],
   "source": [
    "# See how your model is doing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD18RKjYTFXP"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Keras models always output floats, not integers.  In this case the final sigmoid activation function will return a number between 0 and 1.  If the number is closer to 1, the model predicts the sample is more likely to be class 1.  If it is closer to 2, the sample is predicted to be more likely to be class 0.  \n",
    "\n",
    "This is similar to the output of .predict_proba() with Scikit-Learn models.\n",
    "\n",
    "### Converting Floats to Ints\n",
    "\n",
    "In order to use Scikit-Learn metrics functions, the float outputs of the model need to be converted to ints.  We don't want to just use `int(pred)` or `pred.astype(int)` because that will just drop the decimal and all our predictions would be 0s.  \n",
    "\n",
    "Instead we want to **round** the predictions to the nearest integer. To round all of the numbers in an array we can use the NumPy function, `np.rint()` which is short for 'round to integer'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1669774968400,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "HttQV2phV-Va",
    "outputId": "6a5efda7-d513-41e8-9b86-0ac20355218c"
   },
   "outputs": [],
   "source": [
    "model.predict(X_train)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1669775033351,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "u1CSEpv4YXV7",
    "outputId": "d511432b-070f-443f-bdfb-8b6143a9df5b"
   },
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "\n",
    "\n",
    "\n",
    "# round predictions to integers instead of floats using np.rint()\n",
    "\n",
    "\n",
    "# the following code should show whole number predictions, 1.0 or 0.0\n",
    "print(test_preds[:5])\n",
    "print(train_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 943
    },
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1669775050089,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "sov8ZJUHP-Bf",
    "outputId": "e4c9bda5-8b2a-4733-bf59-1a942c15bff5"
   },
   "outputs": [],
   "source": [
    "# Define labels for the confusion matrix\n",
    "labels = ['No Diabetes', 'Diabetes']\n",
    "\n",
    "train_scores = eval_classification(y_train, train_preds, \n",
    "                                   name='base_class_model_train',\n",
    "                                  labels=labels)\n",
    "test_scores = eval_classification(y_test, test_preds, \n",
    "                                   name='base_class_model_test',\n",
    "                                  labels=labels)\n",
    "class_scores = pd.concat([train_scores, test_scores])\n",
    "class_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFvHcmtIsSCy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1AMkk4AkOwuh0L19EdXpLJHJaeZXCP6kQ",
     "timestamp": 1654554871276
    },
    {
     "file_id": "1HZQ_jeFRQsrlNGjvh_ru52Q-1DhIahua",
     "timestamp": 1636586978598
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "243.829px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
